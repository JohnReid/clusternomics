{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "# ed.set_seed(37)\n",
    "# np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from edward.models import Bernoulli, Beta\n",
    "\n",
    "def dirichlet_process(alpha):\n",
    "    \n",
    "  def cond(k, beta_k):\n",
    "    flip = Bernoulli(p=beta_k)\n",
    "    return tf.equal(flip, tf.constant(1))\n",
    "\n",
    "  def body(k, beta_k):\n",
    "    beta_k = beta_k * Beta(a=1.0, b=alpha)\n",
    "    return k + 1, beta_k\n",
    "\n",
    "  k = tf.constant(0)\n",
    "  beta_k = Beta(a=1.0, b=alpha)\n",
    "  stick_num, stick_beta = tf.while_loop(cond, body, loop_vars=[k, beta_k])\n",
    "  return stick_num\n",
    "\n",
    "\n",
    "dp = dirichlet_process(alpha=.1)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "c = lambda i, s: tf.less_equal(i, 7)\n",
    "b = lambda i, s: (tf.add(i, 1), tf.add(s, i))\n",
    "i = tf.constant(0)\n",
    "s = tf.constant(0)\n",
    "r = tf.while_loop(c, b, loop_vars=[i, s])\n",
    "sess = tf.Session()\n",
    "print(sess.run(r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from edward.models import Bernoulli, Beta, Normal\n",
    "\n",
    "\n",
    "def dirichlet_process(alpha, base_cls, sample_n=50, *args, **kwargs):\n",
    "  \"\"\"Dirichlet process DP(``alpha``, ``base_cls(*args, **kwargs)``).\n",
    "\n",
    "  Only works for scalar alpha and scalar base distribution.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  alpha : tf.Tensor\n",
    "    Concentration parameter. Its shape determines the batch shape of the DP.\n",
    "  base_cls : RandomVariable\n",
    "    Class of base distribution. Its shape (when instantiated)\n",
    "    determines the event shape of the DP.\n",
    "  sample_n : int, optional\n",
    "    Number of samples for each DP in the batch shape.\n",
    "  *args, **kwargs : optional\n",
    "    Arguments passed into ``base_cls``.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  tf.Tensor\n",
    "    A ``tf.Tensor`` of shape ``[sample_n] + batch_shape + event_shape``,\n",
    "    where ``sample_n`` is the number of samples for each DP,\n",
    "    ``batch_shape`` is the number of independent DPs, and\n",
    "    ``event_shape`` is the shape of the base distribution.\n",
    "  \"\"\"\n",
    "  def cond(k, beta_k, draws, bools):\n",
    "    # Proceed if at least one bool is True.\n",
    "    return tf.reduce_any(bools)\n",
    "\n",
    "  def body(k, beta_k, draws, bools):\n",
    "    k = k + 1\n",
    "    beta_k = beta_k * Beta(a=1.0, b=alpha)\n",
    "    theta_k = base_cls(*args, **kwargs)\n",
    "\n",
    "    # Assign ongoing samples to the new theta_k.\n",
    "    indicator = tf.cast(bools, draws.dtype)\n",
    "    new = indicator * theta_k\n",
    "    draws = draws * (1.0 - indicator) + new\n",
    "\n",
    "    flips = tf.cast(Bernoulli(p=beta_k), tf.bool)\n",
    "    bools = tf.logical_and(flips, tf.equal(draws, theta_k))\n",
    "    return k, beta_k, draws, bools\n",
    "\n",
    "  k = 0\n",
    "  beta_k = Beta(a=tf.ones(sample_n), b=alpha * tf.ones(sample_n))\n",
    "  theta_k = base_cls(*args, **kwargs)\n",
    "\n",
    "  # Initialize all samples as theta_k.\n",
    "  draws = tf.ones(sample_n) * theta_k\n",
    "  # Flip ``sample_n`` coins, one for each sample.\n",
    "  flips = tf.cast(Bernoulli(p=beta_k), tf.bool)\n",
    "  # Get boolean tensor for samples that return heads\n",
    "  # and are currently equal to theta_k.\n",
    "  bools = tf.logical_and(flips, tf.equal(draws, theta_k))\n",
    "\n",
    "  total_sticks, _, samples, _ = tf.while_loop(\n",
    "      cond, body, loop_vars=[k, beta_k, draws, bools])\n",
    "  return total_sticks, samples\n",
    "\n",
    "\n",
    "dp = dirichlet_process(0.1, Normal, mu=0.0, sigma=1.0)\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/A96fQ022RKpZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f12c621dcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dpdraw = sess.run(dp)\n",
    "unique, counts = np.unique(dpdraw[1], return_counts = True)\n",
    "plt.bar(unique, counts, width=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_24:0\", shape=(1,), dtype=int64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    492\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         % (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    590\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int64 for Tensor with dtype int32: 'Tensor(\"strided_slice_6/stack_2:0\", shape=(1,), dtype=int32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b981dd54e8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# draw = sess.run(sample())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# print(draw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-b981dd54e8b1>\u001b[0m in \u001b[0;36mpmax\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mamax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maflat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_SliceHelper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   3686\u001b[0m                                 \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3687\u001b[0m                                 \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3688\u001b[0;31m                                 shrink_axis_mask=shrink_axis_mask, name=name)\n\u001b[0m\u001b[1;32m   3689\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    520\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 522\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'."
     ]
    }
   ],
   "source": [
    "base_cls = Normal\n",
    "alpha = tf.constant([.1, 1, 10])  # Have 3 Dirichlet processes\n",
    "logits = tf.zeros(shape=alpha.shape)\n",
    "stickbreaks = tf.zeros(alpha.shape)\n",
    "\n",
    "def sample():\n",
    "    \"\"\"Sample one item from the draw from the Dirichlet process.\"\"\"\n",
    "    p = tf.random_uniform(alpha.shape)\n",
    "    \n",
    "    def cond(s):\n",
    "        # Proceed if any p is greater than all s\n",
    "        return tf.reduce_any(p.greater(s))\n",
    "\n",
    "    def body(s):\n",
    "        beta = Beta(a=1.0 * tf.ones(alpha.shape), b=alpha)\n",
    "        \n",
    "        # Take proportion of remaining stick\n",
    "        lastps = s[-1]  # use correct indexing here\n",
    "        remainders = tf.ones((,)) - lastps\n",
    "        s.concat(s, lastps + remainders * beta)\n",
    "\n",
    "        # Assign ongoing samples to the new theta_k.\n",
    "        theta = base_cls(*args, **kwargs)\n",
    "        indicator = tf.cast(bools, draws.dtype)\n",
    "        new = indicator * theta_k\n",
    "        draws = draws * (1.0 - indicator) + new\n",
    "\n",
    "        flips = tf.cast(Bernoulli(p=beta_k), tf.bool)\n",
    "        bools = tf.logical_and(flips, tf.equal(draws, theta_k))\n",
    "        return k, beta_k, draws, bools\n",
    "\n",
    "    total_sticks, _, samples, _ = tf.while_loop(\n",
    "      cond, body, loop_vars=[k, beta_k, draws, bools])\n",
    "\n",
    "def pmax(a):\n",
    "    aflat = tf.reshape(a, [-1])\n",
    "    idx = tf.reshape(tf.argmax(aflat, 0), [1,])\n",
    "    print(idx)\n",
    "    return aflat, idx, aflat[idx]\n",
    "    amax = aflat[tf.cast(idx, tf.int64)]\n",
    "    return aflat\n",
    "\n",
    "sess = tf.Session()\n",
    "# draw = sess.run(sample())\n",
    "# print(draw)\n",
    "sess.run(pmax(tf.random_uniform([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 11.23747063],\n",
       "       [  9.15561962],\n",
       "       [  9.43934631],\n",
       "       [  8.49564362],\n",
       "       [  8.63346863],\n",
       "       [ 12.43154335],\n",
       "       [ 13.26533985],\n",
       "       [ 12.11446762],\n",
       "       [  8.77148151],\n",
       "       [ 11.06395149]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edward.models import RandomVariable, Categorical, Mixture, MultivariateNormalDiag\n",
    "from tensorflow.contrib.distributions import Distribution\n",
    "from tensorflow.contrib.distributions.python.ops import distribution_util\n",
    "\n",
    "class DirichletProcessSB(RandomVariable, Distribution):\n",
    "    \"\"\"A Dirichlet process implemented using a stick-breaking construction.\n",
    "    \n",
    "    Each sample/value is a `Mixture` distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha = tf.ones([1])):\n",
    "        self.alpha = alpha\n",
    "        super(DirichletProcessSB, self).__init__(\n",
    "            dtype = None,  # No type enforcement\n",
    "            is_continuous = False,\n",
    "            is_reparameterized = False,\n",
    "            validate_args = False,\n",
    "            allow_nan_stats = True,\n",
    "            parameters = {alpha: self.alpha},\n",
    "            name = 'DP')\n",
    "\n",
    "    @distribution_util.AppendDocstring(\"Some other details.\")\n",
    "    def _log_prob(self, value):\n",
    "        raise NotImplementedError(\"log_prob is not implemented\")\n",
    "\n",
    "    @distribution_util.AppendDocstring(\"Some other details.\")\n",
    "    def _sample_n(self, n, seed=None):\n",
    "        if seed is not None:\n",
    "            raise ValueError('Do not know how to use specified seed')\n",
    "        print(n)\n",
    "        K = 3\n",
    "        cat = Categorical(logits=tf.zeros([n, K]))\n",
    "        components = [\n",
    "            MultivariateNormalDiag(\n",
    "                mu = tf.ones([n, 1]) * (k + 10),\n",
    "                diag_stdev = tf.ones([n, 1]))\n",
    "            for k in range(K)]\n",
    "        return Mixture(cat=cat, components=components)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '<DirichletProcessSB: {}>'.format(id(self))\n",
    "\n",
    "pi = DirichletProcessSB()\n",
    "pi\n",
    "sess = tf.Session()\n",
    "sess.run(pi._sample_n(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 0 for 'cond_6/concat' (op: 'ConcatV2') with input shapes: [0], [], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    669\u001b[0m           \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors_as_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           status)\n\u001b[0m\u001b[1;32m    671\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 0 for 'cond_6/concat' (op: 'ConcatV2') with input shapes: [0], [], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-58d9e293bca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mstick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStickBreakingPrior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-173-58d9e293bca1>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_component\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             lambda: choice - 1)  # Take one off as logits for remainder of stick are first\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mstick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStickBreakingPrior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, fn1, fn2, name)\u001b[0m\n\u001b[1;32m   1757\u001b[0m     \u001b[0mcontext_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCondContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m     \u001b[0morig_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m     \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExitResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m     \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[0;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m     \u001b[0moriginal_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-58d9e293bca1>\u001b[0m in \u001b[0;36m_new_component\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetaprime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisbetaprime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetaprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetaprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthisbetaprime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Recalculate logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1050\u001b[0m   return gen_array_ops._concat_v2(values=values,\n\u001b[1;32m   1051\u001b[0m                                   \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m                                   name=name)\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_concat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \"\"\"\n\u001b[1;32m    518\u001b[0m   result = _op_def_lib.apply_op(\"ConcatV2\", values=values, axis=axis,\n\u001b[0;32m--> 519\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    520\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    761\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    762\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2395\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2398\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1755\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/Dev/clusternomics/inst/python/clusternomics/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 0 for 'cond_6/concat' (op: 'ConcatV2') with input shapes: [0], [], []."
     ]
    }
   ],
   "source": [
    "from edward.models import Categorical\n",
    "\n",
    "def stick_breaking_prior(beta, )\n",
    "\n",
    "class StickBreakingPrior(object):\n",
    "    \n",
    "    def __init__(self, a, b):\n",
    "        self.beta = Beta(a, b)\n",
    "\n",
    "        # The stick breaking proportions sampled so far\n",
    "        self.betaprime = tf.zeros(shape = (0,), dtype=tf.float32)  # Initialise to empty tensor\n",
    "\n",
    "        # The logits for each broken part of stick and remainder,\n",
    "        self.logits = tf.zeros(shape = (1,))  # Initialise just representing remainder\n",
    "\n",
    "        # The amount of stick remaining\n",
    "        self.remaining = tf.ones((1,))  # Initialise to one\n",
    "\n",
    "    def _new_component(self):\n",
    "        # Sample a new betaprime\n",
    "        thisbetaprime = self.beta.sample()\n",
    "        self.betaprime = tf.concat((self.betaprime, thisbetaprime), 0)\n",
    "        \n",
    "        # Recalculate logits\n",
    "        newremainder = self.remaining * (1. - thisbetaprime)\n",
    "        compsize = self.remaining * thisbetaprime\n",
    "        self.logits[-1] = self.log(newremainder)\n",
    "        self.logits = tf.concat((self.logits, tf.ones(()) * tf.log(compsize)), 0)\n",
    "        \n",
    "        return self._num_components()\n",
    "    \n",
    "    def _num_components(self):\n",
    "        return self.logits.shape[0] - 1\n",
    "        \n",
    "    def sample(self):\n",
    "        # Sample another broken part or remainder\n",
    "        choice = Categorical(logits = self.logits).sample()\n",
    "\n",
    "        # Did we sample an existing component or do we need to break some\n",
    "        # more stick?\n",
    "        comp = tf.cond(\n",
    "            tf.equal(self._num_components(), choice), \n",
    "            self._new_component,\n",
    "            lambda: choice - 1)  # Take one off as logits for remainder of stick are first\n",
    "        \n",
    "stick = StickBreakingPrior(tf.ones(()), tf.ones(()))        \n",
    "\n",
    "sess.run(stick.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty = tf.zeros(shape = (3,))\n",
    "scalar = tf.ones((2,))\n",
    "concatd = tf.concat((empty, scalar), 0)\n",
    "sess = tf.Session()\n",
    "sess.run(concatd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
